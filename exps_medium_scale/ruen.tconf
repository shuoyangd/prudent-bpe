##################################################################################################
# Packages used
##################################################################################################

package sockeye :: .versioner=git .repo="https://github.com/mjpost/sockeye" .ref=HEAD { }
package sacrebleu :: .versioner=pip .package="sacrebleu" .tag="1.2.12" { }
package subword_nmt :: .versioner=pip .package="subword-nmt" .tag="0.3.5" { }
package mosesdecoder :: .versioner=disk .path="/home/shuoyangd/mosesstd" .ref=HEAD { }

package sentencepiece :: .versioner=git .repo="https://github.com/google/sentencepiece" .ref="tags/v0.1.5" {  # v0.1.6 throws segfault
  mkdir build
  cd build
  cmake ..
  make -j $(nproc)
}

package tools
    :: .versioner=git .repo="https://github.com/shuoyangd/tape4nmt-tools" .ref=HEAD {
  pip install -r requirements.txt
}

# using my fork for now, as fairseq evolves pretty fast
package fairseq
    :: .versioner=git .path="https://github.com/shuoyangd/fairseq" .ref="prudent-bpe" {

  pip install --editable .
  # python setup.py build develop
}

global {

  ##################################################################################################
  # Data-related stuff
  ##################################################################################################

  SRC=(TrainDataSource:
    wmt2017_all_without_UN="ru"
  )
  TRG=(TrainDataSource:
    wmt2017_all_without_UN="en"
  )
  trg_lang=en  # FIXME (only used by wrap_xml, under some rare cases)

  train_data=(TrainDataSource:
    wmt2017_all_without_UN=(side:
      src="/home/shuoyangd/projects/bpe_revisit2/exps_medium_scale/data/train.ru"
      trg="/home/shuoyangd/projects/bpe_revisit2/exps_medium_scale/data/train.en"
    )
  )

  dev_data=(DevDataSource:
    wmt2012=(side:
      src="/export/b18/shuoyangd/data/wmt2019/dev/newstest2012-src.ru.sgm"
      trg="/export/b18/shuoyangd/data/wmt2019/dev/newstest2012-ref.en.sgm"
    )
    wmt2013=(side:
      src="/export/b18/shuoyangd/data/wmt2019/dev/newstest2013-src.ru.sgm"
      trg="/export/b18/shuoyangd/data/wmt2019/dev/newstest2013-ref.en.sgm"
    )
    wmt2014=(side:
      src="/export/b18/shuoyangd/data/wmt2019/dev/newstest2014-ruen-src.ru.sgm"
      trg="/export/b18/shuoyangd/data/wmt2019/dev/newstest2014-ruen-ref.en.sgm"
    )
    wmt2015=(side:
      src="/export/b18/shuoyangd/data/wmt2019/dev/newstest2015-ruen-src.ru.sgm"
      trg="/export/b18/shuoyangd/data/wmt2019/dev/newstest2015-ruen-ref.en.sgm"
    )
    wmt2016=(side:
      src="/export/b18/shuoyangd/data/wmt2019/dev/newstest2016-ruen-src.ru.sgm"
      trg="/export/b18/shuoyangd/data/wmt2019/dev/newstest2016-ruen-ref.en.sgm"
    )
  )

  test_data=(TestDataSource:
    wmt2017=(side:
      src="/export/b18/shuoyangd/data/wmt2019/dev/newstest2017-ruen-src.ru.sgm"
      trg="/export/b18/shuoyangd/data/wmt2019/dev/newstest2017-ruen-ref.en.sgm"
    )
  )

  ##################################################################################################
  # General options you should set for your environment
  ##################################################################################################

  # All ducttape files will be written underneath this directory
  ducttape_output="out_ruen"

  # TRAINING CONFIGURATIONS
  # all default is consistent with nematus
  train_train_from="" # if there is a previous model to start with
  train_train_from_state_dict="" # if there is a previous dict to start with
  train_start_epoch="" # if trained for certain amount of epochs previously

  train_batch_size="80"
  train_optim="adam"
  train_dropout=(Dropout: 0.1 0.3 0.5)
  train_lr="0.001"
  train_lr_min="9e-8"
  train_keep_last_N_checkpoints="4"
  # train_lr_min=""
  train_lr_shrink="0.5"
  train_lr_scheduler=(LrScheduler: Default="" Transformer="inverse_sqrt")
  train_warmup_init_lr=(WarmUpLr: Default="" Transformer="1e-07")
  train_warmup_updates=(WarmUpUpdates: Default="" Transformer="4000")
  train_criterion=(Criterion: CE="" Transformer="label_smoothed_cross_entropy")
  train_label_smoothing=(LabelSmoothing: Default="" Transformer="0.1")
  train_clip_norm=(ClipNorm: 0.0 0.1 0.5 1 5)
  train_max_tokens="4000"
  train_max_epochs="100"
  train_weight_decay=(WeightDecay: Default="" Transformer="0.0")
  train_update_freq=(UpdateFreq: Default="" Transformer="16")
  train_seed=""
  train_arch=(Architecture: conv="fconv" transformer="transformer" fconv_iwslt_de_en="fconv_iwslt_de_en" transformer_iwslt_de_en="transformer_iwslt_de_en" transformer_wmt_en_de="transformer_wmt_en_de" fconv_wmt_en_de="fconv_wmt_en_de" lstm_wiseman_iwslt_de_en="lstm_wiseman_iwslt_de_en" lstm_shallow_iwslt_de_en="lstm_shallow_iwslt_de_en")
  train_share_input_output_embed=""
  train_skip_invalid_size_inputs_valid_test="yes"
  train_adam_beta1="0.9"
  train_adam_beta2="0.98"

  # TEST CONFIGURATIONS
  test_model_selection_strategy="acc"
  test_max_sent_length="300"
  test_beam_size="12"
  test_batch_size="32"
  test_replace_unk="True"
  test_remove_bpe=""

  ##################################################################################################
  # Job parameters
  ##################################################################################################

  # your email
  email="adi.r@jhu.edu"

  # SGE: generic job flags
  resource_flags="-l mem_free=2g"

  # SGE: larger job flags
  resource_flags_16g="-l mem_free=16g"

  # SGE: flags for training a model
  resource_flags_train="-q g.q -l gpu=1,mem_free=4g"

  # SGE: flags for decoding
  resource_flags_decode="-q g.q -l gpu=1,mem_free=4g"

  # SGE: flags for notifying about job completion (put in your email address!)
  action_flags="-m ae -M dings@jhu.edu"

  # The default submitter: shell (run locally) or sge (run on a grid)
  submitter=(TestMode: no="sge" yes="shell")

  # Virtual env location. This should be a file path to the virtual env you want loaded before tasks.
  # This variable supports both conda and Python's virtualenv. For conda, use "conda:ENV" as the value,
  # where "ENV" is the name of the conda environment that should be loaded. For virtualenv, supply
  # the path to the script that should be loaded.
  pyenv="/home/shuoyangd/pyenv/py3t/bin/activate"

  ##################################################################################################
  # Preprocessing options
  ##################################################################################################

  # sentencepiece options
  sentencepiece_vocab_size=8000
  sentencepiece_model_type="unigram"

  # no of BPE operations
  bpe_operations=(BpeMergeOps: 1000 2000 4000 8000 16000 32000 0 500)

  # options for cleaning training data
  MaxLen=80
  Ratio=1

  use_cpu=(TestMode: no yes)
}
